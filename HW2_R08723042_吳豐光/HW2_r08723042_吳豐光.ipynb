{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 題目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use LSTM & CNN model to classify MNIST dataset with at least 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 執行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有檔案: mnist_train_all.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use LSTM & CNN model to classify MNIST\n",
    "* mnist_train_all.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes):\n",
    "    x_train = x_train.reshape(-1, n_step, n_input)\n",
    "    x_test = x_test.reshape(-1, n_step, n_input)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "def cnn_preprocess(x_train, x_test, y_train, y_test):\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "def lstm_model(n_input, n_step, n_hidden, n_classes):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_hidden, batch_input_shape=(None, n_step, n_input), unroll=True))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPool2D(strides=2))\n",
    "    model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "    model.add(MaxPool2D(strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def trainning(model, x_train, y_train, x_test, y_test, \n",
    "              learning_rate, training_iters, batch_size):\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size, epochs=training_iters,\n",
    "              verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "def print_confusion_result(x_train, x_test, y_train, y_test, model):\n",
    "    # get train & test predictions\n",
    "    train_pred = model.predict_classes(x_train)\n",
    "    test_pred = model.predict_classes(x_test)\n",
    "    \n",
    "    # get train & test true labels\n",
    "    train_label = y_train\n",
    "    test_label =  y_test\n",
    "    \n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(10))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(10))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)\n",
    "\n",
    "def mnist_lstm_main():\n",
    "    # training parameters\n",
    "    learning_rate = 0.001\n",
    "    training_iters = 1\n",
    "    batch_size = 128\n",
    "\n",
    "    # model parameters\n",
    "    n_input = 28\n",
    "    n_step = 28\n",
    "    n_hidden = 256\n",
    "    n_classes = 10\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test, y_train_o, y_test_o = lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes)\n",
    "\n",
    "    model = lstm_model(n_input, n_step, n_hidden, n_classes)\n",
    "    trainning(model, x_train, y_train_o, x_test, y_test_o, learning_rate, training_iters, batch_size)\n",
    "    scores = model.evaluate(x_test, y_test_o, verbose=0)\n",
    "    print('LSTM test accuracy:', scores[1])\n",
    "    print_confusion_result(x_train, x_test, y_train, y_test, model)\n",
    "\n",
    "def mnist_cnn_main():\n",
    "    # training parameters\n",
    "    learning_rate = 0.001\n",
    "    training_iters = 1\n",
    "    batch_size = 64\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test, y_train_o, y_test_o = cnn_preprocess(x_train, x_test, y_train, y_test)\n",
    "\n",
    "    model = cnn_model()\n",
    "    trainning(model, x_train, y_train_o, x_test, y_test_o, learning_rate, training_iters, batch_size)\n",
    "    scores = model.evaluate(x_test, y_test_o, verbose=0)\n",
    "    print('CNN test accuracy:', scores[1])\n",
    "    print_confusion_result(x_train, x_test, y_train, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 256)               291840    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 294,410\n",
      "Trainable params: 294,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "469/469 [==============================] - 25s 49ms/step - loss: 0.8435 - accuracy: 0.7108 - val_loss: 0.1418 - val_accuracy: 0.9559\n",
      "LSTM test accuracy: 0.9559000134468079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Allan Ngo\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5797    1   11    2   12    7   28    2   33   30]\n",
      " [   2 6589   54    9   24    0   16   24   18    6]\n",
      " [  18    6 5784   25   22    4   13   44   34    8]\n",
      " [   6   19  145 5711    2   35    4   44  148   17]\n",
      " [   5    6   11    2 5559    5   30   62   23  139]\n",
      " [  35   11   28   70    4 5156   73    5   31    8]\n",
      " [  43    4   24    0   71   32 5717    0   24    3]\n",
      " [   7    9   94   15    9    4    0 6058   12   57]\n",
      " [  16   25   51  124   26  114   39    1 5436   19]\n",
      " [  19    3   25   43  118   31    5   88   84 5533]] \n",
      "\n",
      " [[ 963    0    1    0    2    2    6    1    2    3]\n",
      " [   0 1118    5    1    0    0    6    0    5    0]\n",
      " [   5    0 1001    5    1    1    3    9    7    0]\n",
      " [   0    2   20  960    0    5    0    9   14    0]\n",
      " [   0    0    2    1  939    4    9    6    1   20]\n",
      " [   6    0    2   17    0  843   14    1    9    0]\n",
      " [  16    2    2    0   20    6  907    0    4    1]\n",
      " [   0    3   23    5    0    0    0  980    6   11]\n",
      " [   6    0    4   28    5   19    4    2  904    2]\n",
      " [   5    3    2    4   12    5    1    9   24  944]]\n"
     ]
    }
   ],
   "source": [
    "mnist_lstm_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 48)        38448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               307456    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                21588     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 369,174\n",
      "Trainable params: 369,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.3227 - accuracy: 0.8974 - val_loss: 0.0387 - val_accuracy: 0.9879\n",
      "CNN test accuracy: 0.9879000186920166\n",
      "[[5868    3    6    0    6    0   31    5    3    1]\n",
      " [   0 6715   12    0    0    0    0   12    2    1]\n",
      " [   3   12 5903    0    2    0    1   21   12    4]\n",
      " [   2    3   58 5986    0   13    1   17   43    8]\n",
      " [   1   30    1    0 5772    0    6    5    2   25]\n",
      " [   6    7    3   14    2 5289   32    5   56    7]\n",
      " [   4    8    2    0    5    3 5885    0   11    0]\n",
      " [   0    8   18    1    2    2    0 6223    5    6]\n",
      " [   5   21    9    2    8    2    7    4 5782   11]\n",
      " [   6   11    1    4   23   10    0   53   23 5818]] \n",
      "\n",
      " [[ 973    1    0    0    1    0    2    2    1    0]\n",
      " [   0 1130    2    0    0    0    0    2    1    0]\n",
      " [   1    0 1025    0    0    0    0    2    4    0]\n",
      " [   0    0    2  995    0    3    0    4    6    0]\n",
      " [   0    1    0    0  971    0    1    0    0    9]\n",
      " [   2    0    1    7    0  872    5    1    3    1]\n",
      " [   1    3    0    0    1    1  948    0    4    0]\n",
      " [   0    2    7    2    0    0    0 1015    1    1]\n",
      " [   3    0    2    0    1    0    0    1  966    1]\n",
      " [   0    5    1    0    5    2    0    8    4  984]]\n"
     ]
    }
   ],
   "source": [
    "mnist_cnn_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "-PecuLab Github"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
