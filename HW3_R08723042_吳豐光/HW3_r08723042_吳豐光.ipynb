{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 題目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use LSTM & CNN model to classify customized candlestick pattern (at least 3 classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 執行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有檔案: candlestick_train_cnn.py、candlestick_train_lstm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use LSTM model to classify customized candlestick pattern\n",
    "* candlestick_train_lstm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def load_pkl(pkl_name):\n",
    "    # load data from data folder\n",
    "    with open(pkl_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes):\n",
    "    x_train = x_train.reshape(-1, n_step, n_input)\n",
    "    x_test = x_test.reshape(-1, n_step, n_input)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "def lstm_model(n_input, n_step, n_hidden, n_classes):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_hidden, batch_input_shape=(None, n_step, n_input), unroll=True))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "def train_lstm(model, x_train, y_train, x_test, y_test, \n",
    "        learning_rate, training_iters, batch_size):\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=adam,\n",
    "        loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "        batch_size=batch_size, epochs=training_iters,\n",
    "        verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "def print_result(data, x_train, x_test, model):\n",
    "    # get train & test pred-labels\n",
    "    train_pred = model.predict_classes(x_train)\n",
    "    test_pred = model.predict_classes(x_test)\n",
    "    # get train & test true-labels\n",
    "    train_label = data['train_label'][:, 0]\n",
    "    test_label = data['test_label'][:, 0]\n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(9))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(9))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)\n",
    "\n",
    "def candlestick_lstm_main(iters):\n",
    "    # training parameters\n",
    "    learning_rate = 0.001\n",
    "    training_iters = iters\n",
    "    batch_size = 128\n",
    "\n",
    "    # model parameters\n",
    "    n_input = 40\n",
    "    n_step = 10\n",
    "    n_hidden = 256\n",
    "    n_classes = 10\n",
    "\n",
    "    data = load_pkl('./data/label8_eurusd_10bar_1500_500_val200_gaf_culr.pkl')\n",
    "    x_train, y_train, x_test, y_test = data['train_gaf'], data['train_label'][:, 0], data['test_gaf'], data['test_label'][:, 0]\n",
    "    x_train, x_test, y_train, y_test = lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes)\n",
    "\n",
    "    model = lstm_model(n_input, n_step, n_hidden, n_classes)\n",
    "    train_lstm(model, x_train, y_train, x_test, y_test, learning_rate, \n",
    "               training_iters, batch_size)\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('LSTM test accuracy:', scores[1])\n",
    "    print_result(data, x_train, x_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 256)               304128    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 306,698\n",
      "Trainable params: 306,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "118/118 [==============================] - 3s 20ms/step - loss: 2.2044 - accuracy: 0.1951 - val_loss: 1.5961 - val_accuracy: 0.2810\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 1.5521 - accuracy: 0.3210 - val_loss: 1.5523 - val_accuracy: 0.2882\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 1.3712 - accuracy: 0.3908 - val_loss: 1.2668 - val_accuracy: 0.4484\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 1.2138 - accuracy: 0.4902 - val_loss: 1.1062 - val_accuracy: 0.5436\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 1.0043 - accuracy: 0.6143 - val_loss: 0.8275 - val_accuracy: 0.6838\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 0.8274 - accuracy: 0.6799 - val_loss: 0.6237 - val_accuracy: 0.7670\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 0.6933 - accuracy: 0.7272 - val_loss: 0.5643 - val_accuracy: 0.7900\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 0.6439 - accuracy: 0.7438 - val_loss: 0.5260 - val_accuracy: 0.7994\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 2s 19ms/step - loss: 0.6137 - accuracy: 0.7660 - val_loss: 0.5186 - val_accuracy: 0.8070\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 2s 19ms/step - loss: 0.5771 - accuracy: 0.7793 - val_loss: 0.7289 - val_accuracy: 0.7170\n",
      "LSTM test accuracy: 0.7170000076293945\n",
      "[[1441  114  220   42  135  299  549   64  136]\n",
      " [ 516  983    0    0    0    0    1    0    0]\n",
      " [  59    0 1245    0  194    0    1    0    1]\n",
      " [ 147  290    0  897    0    0    0  166    0]\n",
      " [   3    0   30    0  745    0    1    0  721]\n",
      " [ 201    5    2    1    0 1261    2   28    0]\n",
      " [   9    0    1    0    0    0 1450    0   40]\n",
      " [ 126   21    0  127    0   84    0 1142    0]\n",
      " [   2    0    3    0   30    0  170    0 1295]] \n",
      "\n",
      " [[480  37  88  13  45  96 169  20  52]\n",
      " [152 348   0   0   0   0   0   0   0]\n",
      " [ 14   0 409   0  76   0   0   0   1]\n",
      " [ 48 117   0 288   0   0   0  47   0]\n",
      " [  3   0  12   0 274   0   1   0 210]\n",
      " [ 67   0   0   0   0 433   0   0   0]\n",
      " [  1   0   0   0   1   0 493   0   5]\n",
      " [ 35   2   0  15   0  24   0 424   0]\n",
      " [  1   0   0   0   0   0  63   0 436]]\n"
     ]
    }
   ],
   "source": [
    "candlestick_lstm_main(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 256)               304128    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 306,698\n",
      "Trainable params: 306,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "118/118 [==============================] - 3s 19ms/step - loss: 2.2063 - accuracy: 0.1975 - val_loss: 1.6521 - val_accuracy: 0.2698\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 1.6494 - accuracy: 0.2930 - val_loss: 1.5042 - val_accuracy: 0.3286\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 2s 19ms/step - loss: 1.3765 - accuracy: 0.3886 - val_loss: 1.4771 - val_accuracy: 0.3398\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 1.2911 - accuracy: 0.4226 - val_loss: 1.2622 - val_accuracy: 0.4302\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 1.2351 - accuracy: 0.4443 - val_loss: 1.2768 - val_accuracy: 0.4564\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 1.1792 - accuracy: 0.4946 - val_loss: 1.2068 - val_accuracy: 0.5062\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 1.1629 - accuracy: 0.5180 - val_loss: 1.1774 - val_accuracy: 0.4912\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 1.1241 - accuracy: 0.5281 - val_loss: 1.2936 - val_accuracy: 0.4676\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 1.0649 - accuracy: 0.5725 - val_loss: 0.7087 - val_accuracy: 0.7302\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 0.7741 - accuracy: 0.6952 - val_loss: 0.7429 - val_accuracy: 0.6978\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.6466 - accuracy: 0.7478 - val_loss: 0.7244 - val_accuracy: 0.7074\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 0.6338 - accuracy: 0.7538 - val_loss: 0.4955 - val_accuracy: 0.8162\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.5955 - accuracy: 0.7698 - val_loss: 0.4961 - val_accuracy: 0.8180\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.5660 - accuracy: 0.7821 - val_loss: 0.6542 - val_accuracy: 0.7560\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.5877 - accuracy: 0.7724 - val_loss: 0.5106 - val_accuracy: 0.8148\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.5931 - accuracy: 0.7682 - val_loss: 0.4687 - val_accuracy: 0.8318\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 0.5166 - accuracy: 0.8039 - val_loss: 0.5261 - val_accuracy: 0.7992\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 0.5192 - accuracy: 0.8013 - val_loss: 0.4402 - val_accuracy: 0.8412\n",
      "Epoch 19/20\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.5238 - accuracy: 0.7992 - val_loss: 0.4272 - val_accuracy: 0.8448\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 2s 17ms/step - loss: 0.4750 - accuracy: 0.8218 - val_loss: 0.4842 - val_accuracy: 0.8196\n",
      "LSTM test accuracy: 0.819599986076355\n",
      "[[1991   75  261   94   91  112  145   98  133]\n",
      " [ 143 1278    0   77    0    0    2    0    0]\n",
      " [  43    0 1457    0    0    0    0    0    0]\n",
      " [  79   18    0 1005    0    2    0  396    0]\n",
      " [  20    0  196    0 1225    0    0    0   59]\n",
      " [ 155    1    1    0    0 1324    2   17    0]\n",
      " [  60    1    3    0    5    0 1318    0  113]\n",
      " [  99    1    0   66    0   36    0 1298    0]\n",
      " [  17    0    9    0  273    0    8    0 1193]] \n",
      "\n",
      " [[672  20  92  36  33  45  39  30  33]\n",
      " [ 39 435   0  26   0   0   0   0   0]\n",
      " [ 13   0 487   0   0   0   0   0   0]\n",
      " [ 27   4   0 347   0   0   0 122   0]\n",
      " [  6   0  85   0 394   0   0   0  15]\n",
      " [ 61   0   0   0   0 438   0   1   0]\n",
      " [ 26   0   1   0   0   0 435   0  38]\n",
      " [ 20   0   0   2   0  12   0 466   0]\n",
      " [  5   0   0   0  70   0   1   0 424]]\n"
     ]
    }
   ],
   "source": [
    "candlestick_lstm_main(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM method with 10 and 20 iterations\n",
    "* the both final round wouldn't change a lot\n",
    "* the LSTM test accuracy is 0.717 and 0.8196 respectivily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use CNN model to classify customized candlestick pattern\n",
    "* candlestick_train_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, Activation, MaxPool2D\n",
    "\n",
    "\n",
    "def load_pkl(pkl_name):\n",
    "    # load data from data folder\n",
    "    with open(pkl_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def get_cnn_model(params):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(10, 10, 4)))\n",
    "    model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def train_model(params, data):\n",
    "    model = get_cnn_model(params)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    hist = model.fit(x=data['train_gaf'], y=data['train_label_arr'],\n",
    "                     batch_size=params['batch_size'], epochs=params['epochs'], verbose=2)\n",
    "    return (model, hist)\n",
    "\n",
    "def print_result(data, model):\n",
    "    # get train & test pred-labels\n",
    "    train_pred = model.predict_classes(data['train_gaf'])\n",
    "    test_pred = model.predict_classes(data['test_gaf'])\n",
    "    # get train & test true-labels\n",
    "    train_label = data['train_label'][:, 0]\n",
    "    test_label = data['test_label'][:, 0]\n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(9))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(9))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 - 2s - loss: 1.6311 - accuracy: 0.3929\n",
      "Epoch 2/10\n",
      "235/235 - 2s - loss: 0.7968 - accuracy: 0.7135\n",
      "Epoch 3/10\n",
      "235/235 - 2s - loss: 0.6037 - accuracy: 0.7801\n",
      "Epoch 4/10\n",
      "235/235 - 2s - loss: 0.5258 - accuracy: 0.8085\n",
      "Epoch 5/10\n",
      "235/235 - 2s - loss: 0.4833 - accuracy: 0.8236\n",
      "Epoch 6/10\n",
      "235/235 - 2s - loss: 0.4611 - accuracy: 0.8313\n",
      "Epoch 7/10\n",
      "235/235 - 2s - loss: 0.4373 - accuracy: 0.8425\n",
      "Epoch 8/10\n",
      "235/235 - 2s - loss: 0.4182 - accuracy: 0.8464\n",
      "Epoch 9/10\n",
      "235/235 - 2s - loss: 0.4098 - accuracy: 0.8493\n",
      "Epoch 10/10\n",
      "235/235 - 2s - loss: 0.3944 - accuracy: 0.8561\n",
      "CNN test accuracy: 0.8525999784469604\n",
      "[[1785  212  183  113  136  130  105  184  152]\n",
      " [   4 1496    0    0    0    0    0    0    0]\n",
      " [  16    0 1463    0   21    0    0    0    0]\n",
      " [   8   76    0 1292    0    0    0  124    0]\n",
      " [   5    0   17    0 1152    0    0    0  326]\n",
      " [  36    6    0    2    0 1392    3   61    0]\n",
      " [  50    3    4    0    1    0 1368    0   74]\n",
      " [   5    8    0  121    0    3    0 1363    0]\n",
      " [   2    0    3    0   67    0   20    0 1408]] \n",
      "\n",
      " [[590  63  79  31  43  53  30  67  44]\n",
      " [  1 499   0   0   0   0   0   0   0]\n",
      " [  1   0 497   0   2   0   0   0   0]\n",
      " [  6  25   0 422   0   0   0  47   0]\n",
      " [  5   0  16   0 372   0   0   0 107]\n",
      " [ 13   1   0   0   0 466   0  20   0]\n",
      " [ 24   0   2   0   0   0 454   0  20]\n",
      " [  2   4   0  14   0   0   0 480   0]\n",
      " [  5   0   0   0   6   0   6   0 483]]\n"
     ]
    }
   ],
   "source": [
    "PARAMS = {}\n",
    "PARAMS['pkl_name'] = './data/label8_eurusd_10bar_1500_500_val200_gaf_culr.pkl'\n",
    "PARAMS['classes'] = 9\n",
    "PARAMS['lr'] = 0.01\n",
    "PARAMS['epochs'] = 10\n",
    "PARAMS['batch_size'] = 64\n",
    "PARAMS['optimizer'] = optimizers.SGD(lr=PARAMS['lr'])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# load data & keras model\n",
    "data = load_pkl(PARAMS['pkl_name'])\n",
    "# train cnn model\n",
    "model, hist = train_model(PARAMS, data)\n",
    "# train & test result\n",
    "scores = model.evaluate(data['test_gaf'], data['test_label_arr'], verbose=0)\n",
    "print('CNN test accuracy:', scores[1])\n",
    "print_result(data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN method with 10 iterations\n",
    "* it performs better than LSTM no matter the iterations are the same, or twice as much\n",
    "* the CNN test accuracy is .8526"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "-PecuLab Github"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
